# -*- coding: utf-8 -*-
"""translator_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CunKen-dHtdzqxz7tV4CpigHbq1wcsPh
"""

pip install gtts gradio transformers torchaudio



from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer, pipeline
import gradio as gr

# Load the model and tokenizer
model_name = "facebook/m2m100_418M"
tokenizer = M2M100Tokenizer.from_pretrained(model_name)
model = M2M100ForConditionalGeneration.from_pretrained(model_name)

# Full language names mapped to codes
language_dict = {
    "Afrikaans": "af", "Amharic": "am", "Arabic": "ar", "Azerbaijani": "az",
    "Bengali": "bn", "Bulgarian": "bg", "Catalan": "ca", "Chinese": "zh",
    "Croatian": "hr", "Czech": "cs", "Danish": "da", "Dutch": "nl",
    "English": "en", "Estonian": "et", "Finnish": "fi", "French": "fr",
    "German": "de", "Greek": "el", "Gujarati": "gu", "Hebrew": "he",
    "Hindi": "hi", "Hungarian": "hu", "Icelandic": "is", "Indonesian": "id",
    "Irish": "ga", "Italian": "it", "Japanese": "ja", "Kannada": "kn",
    "Korean": "ko", "Latvian": "lv", "Lithuanian": "lt", "Malayalam": "ml",
    "Marathi": "mr", "Norwegian": "no", "Persian": "fa", "Polish": "pl",
    "Portuguese": "pt", "Punjabi": "pa", "Romanian": "ro", "Russian": "ru",
    "Sanskrit": "sa", "Serbian": "sr", "Sinhala": "si", "Slovak": "sk",
    "Slovenian": "sl", "Spanish": "es", "Swahili": "sw", "Swedish": "sv",
    "Tamil": "ta", "Telugu": "te", "Thai": "th", "Turkish": "tr",
    "Ukrainian": "uk", "Urdu": "ur", "Vietnamese": "vi", "Welsh": "cy",
    "Xhosa": "xh", "Yiddish": "yi", "Zulu": "zu"
}

# Translation function
def translate(text, tgt_language):
    if not text:
        return "‚ùå Error: No input text provided."

    try:
        tgt_lang_code = language_dict.get(tgt_language)
        if not tgt_lang_code:
            return f"‚ùå Error: Invalid target language selected."

        tokenizer.src_lang = "en"
        encoded = tokenizer(text, return_tensors="pt")
        generated_tokens = model.generate(
            **encoded,
            forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang_code]
        )
        return tokenizer.decode(generated_tokens[0], skip_special_tokens=True)
    except Exception as e:
        return f"‚ùå Translation Error: {e}"

# Custom UI CSS with background image and improved readability
custom_css = """
.gradio-container {
    background: url('https://wallpaperaccess.com/full/2662155.jpg') no-repeat center center fixed;
    background-size: cover;
    font-family: 'Segoe UI', sans-serif;
    color: #000;
    padding: 2em;
    max-width: 1000px;
    margin: auto;
    border-radius: 16px;
    box-shadow: 0 0 20px rgba(0,0,0,0.15);
}

.gr-box, textarea, select, input, .gr-button {
    background-color: rgba(255, 255, 255, 0.9) !important;
    border-radius: 10px !important;
    font-size: 16px;
    color: #000 !important;
}

.gr-button {
    background-color: #1f6feb !important;
    color: white !important;
    font-weight: bold;
}

/* ‚úÖ Ensures all text including headers, footers, markdown, etc. are black */
h1, h2, h3, h4, h5, h6,
.gr-markdown, footer, footer *, .prose *, .gr-text, .svelte-1ipelgc {
    color: #000 !important;
}
"""







# Gradio Interface with voice input/output
with gr.Blocks(css=custom_css) as demo:
    gr.Markdown("""# üåê Universal Translator App
    Translate between 100+ languages using Meta's M2M100 model. Just speak or type the text. The source language is auto-detected.
    """)

    with gr.Row():
        with gr.Column():
            input_audio = gr.Audio(type="filepath", label="üéôÔ∏è Speak Audio")
            input_text = gr.Textbox(label="üìù Or Enter Text", placeholder="Type or speak your sentence...")
            target_lang = gr.Dropdown(choices=list(language_dict.keys()), label="üåê Target Language", value="Hindi")
            translate_btn = gr.Button("Translate")

        with gr.Column():
            translated_text = gr.Textbox(label="‚úÖ Translated Text")
            output_audio = gr.Audio(label="üîä Listen to Translation", type="filepath")

    def pipeline_translate(audio_path, text, tgt_lang):
        import tempfile
        from gtts import gTTS
        from transformers import pipeline

        try:
            if audio_path:
                asr = pipeline("automatic-speech-recognition", model="openai/whisper-base")
                transcribed = asr(audio_path)["text"]
            else:
                transcribed = text

            if not transcribed:
                return "‚ùå Please provide text or speak something.", None

            translated = translate(transcribed, tgt_lang)

            if translated.startswith("‚ùå"):
                return translated, None

            tts = gTTS(translated)
            temp_audio_path = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
            tts.save(temp_audio_path.name)

            return translated, temp_audio_path.name
        except Exception as e:
            return f"‚ùå Processing Error: {e}", None

    translate_btn.click(fn=pipeline_translate, inputs=[input_audio, input_text, target_lang], outputs=[translated_text, output_audio])

# Launch with shareable link
demo.launch(share=True)